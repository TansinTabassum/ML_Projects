{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "MkD7KkBBG6mt"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\" Text Generation using LSTM (Next Word Prediction)\n",
        "\n",
        "Natural language is sequential in nature because every\n",
        " word in a sentence depends on the words that come before it.\n",
        "  For example, in the sentence I am going to the market each word follows a meaningful order.\n",
        "  If we change the order randomly, the sentence will lose its meaning.\n",
        "   This sequential dependency makes text data perfect for training an LSTM (Long Short-Term Memory) model.\n",
        "    LSTM is a special type of Recurrent Neural Network (RNN) that is designed to learn long-term dependencies in sequential data.\n",
        "\n",
        "In text generation tasks, the main objective is to predict the next word in a sentence based on previous words.\n",
        "For example, if the input is I love to play , the model may predict the next word as  football or games depending on the training data.\n",
        "The LSTM model learns patterns, grammar, and context from a large amount of text data.\n",
        "It remembers important words from earlier in the sentence and uses that memory to make better predictions.\n",
        " This is why LSTM performs better than traditional RNNs for language-related tasks.\n",
        "\n",
        "To build this model, the text data is first preprocessed.\n",
        " The sentences are converted into lowercase, punctuation is removed, and the text is tokenized (split into words).\n",
        "  Each word is then converted into numerical form using tokenization and padding techniques so that the LSTM model can understand it.\n",
        "   The model is trained on sequences of words where the input is a group of words, and the output is the next word.\n",
        "   Over time, the model learns the probability of which word is most likely to appear next.\n",
        "\n",
        "Text generation using LSTM has many real-world applications.\n",
        " It is used in chatbots, predictive text keyboards, story generation systems, and language translation tools.\n",
        "  For example, when you type a message on your smartphone, the suggested next word is often predicted using models similar to LSTM.\n",
        "   By training on a larger dataset, the model can generate longer and more meaningful sentences.\n",
        "\n",
        "In conclusion, text generation is a simple and effective topic to implement LSTM because text naturally follows a sequential pattern.\n",
        " The dependency between words makes LSTM an ideal model for learning context and predicting future words.\n",
        "  This project is beginner-friendly and can be easily implemented in Google Colab using libraries like TensorFlow or PyTorch.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "xlT4M4d7ZP2Z"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebWi_FY5ZwVo"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "4cr18X_XZYDD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "mJM679YFZbwH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdYvlfM8ZfBg",
        "outputId": "76de48d5-63c8-490d-cfe3-6f72215ea506"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "D27tQau_ZjEc"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7PvwpAgZmdr",
        "outputId": "c37f0c78-e58f-4fe5-8854-e5fd92ec536e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 15],\n",
              " [3, 15, 16],\n",
              " [3, 15, 16, 4],\n",
              " [3, 15, 16, 4, 12],\n",
              " [3, 15, 16, 4, 12, 8],\n",
              " [3, 15, 16, 4, 12, 8, 53],\n",
              " [54, 24],\n",
              " [54, 24, 2],\n",
              " [54, 24, 2, 20],\n",
              " [54, 24, 2, 20, 5],\n",
              " [54, 24, 2, 20, 5, 55],\n",
              " [54, 24, 2, 20, 5, 55, 29],\n",
              " [54, 24, 2, 20, 5, 55, 29, 56],\n",
              " [8, 5],\n",
              " [8, 5, 6],\n",
              " [8, 5, 6, 17],\n",
              " [8, 5, 6, 17, 57],\n",
              " [8, 5, 6, 17, 57, 13],\n",
              " [8, 5, 6, 17, 57, 13, 1],\n",
              " [8, 5, 6, 17, 57, 13, 1, 11],\n",
              " [8, 5, 6, 17, 57, 13, 1, 11, 21],\n",
              " [8, 5, 6, 17, 57, 13, 1, 11, 21, 58],\n",
              " [8, 5, 6, 17, 57, 13, 1, 11, 21, 58, 59],\n",
              " [8, 5, 6, 17, 57, 13, 1, 11, 21, 58, 59, 22],\n",
              " [14, 25],\n",
              " [14, 25, 5],\n",
              " [14, 25, 5, 1],\n",
              " [14, 25, 5, 1, 17],\n",
              " [14, 25, 5, 1, 17, 30],\n",
              " [14, 25, 5, 1, 17, 30, 60],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31, 8],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31, 8, 32],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31, 8, 32, 6],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31, 8, 32, 6, 33],\n",
              " [14, 25, 5, 1, 17, 30, 60, 61, 9, 1, 62, 31, 8, 32, 6, 33, 34],\n",
              " [35, 63],\n",
              " [35, 63, 64],\n",
              " [35, 63, 64, 1],\n",
              " [35, 63, 64, 1, 34],\n",
              " [35, 63, 64, 1, 34, 65],\n",
              " [35, 63, 64, 1, 34, 65, 1],\n",
              " [35, 63, 64, 1, 34, 65, 1, 17],\n",
              " [35, 63, 64, 1, 34, 65, 1, 17, 66],\n",
              " [35, 63, 64, 1, 34, 65, 1, 17, 66, 67],\n",
              " [35, 63, 64, 1, 34, 65, 1, 17, 66, 67, 68],\n",
              " [35, 63, 64, 1, 34, 65, 1, 17, 66, 67, 68, 69],\n",
              " [23, 20],\n",
              " [23, 20, 36],\n",
              " [23, 20, 36, 37],\n",
              " [23, 20, 36, 37, 3],\n",
              " [23, 20, 36, 37, 3, 18],\n",
              " [23, 20, 36, 37, 3, 18, 70],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4, 39],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4, 39, 71],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4, 39, 71, 40],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4, 39, 71, 40, 41],\n",
              " [23, 20, 36, 37, 3, 18, 70, 14, 26, 38, 4, 39, 71, 40, 41, 10],\n",
              " [4, 2],\n",
              " [4, 2, 6],\n",
              " [4, 2, 6, 72],\n",
              " [4, 2, 6, 72, 42],\n",
              " [4, 2, 6, 72, 42, 19],\n",
              " [4, 2, 6, 72, 42, 19, 73],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78, 39],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78, 39, 40],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78, 39, 40, 79],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78, 39, 40, 79, 5],\n",
              " [4, 2, 6, 72, 42, 19, 73, 74, 75, 76, 21, 2, 77, 9, 78, 39, 40, 79, 5, 20],\n",
              " [4,\n",
              "  2,\n",
              "  6,\n",
              "  72,\n",
              "  42,\n",
              "  19,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  21,\n",
              "  2,\n",
              "  77,\n",
              "  9,\n",
              "  78,\n",
              "  39,\n",
              "  40,\n",
              "  79,\n",
              "  5,\n",
              "  20,\n",
              "  18],\n",
              " [5, 3],\n",
              " [5, 3, 15],\n",
              " [5, 3, 15, 43],\n",
              " [5, 3, 15, 43, 1],\n",
              " [5, 3, 15, 43, 1, 80],\n",
              " [5, 3, 15, 43, 1, 80, 81],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6, 17],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6, 17, 82],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6, 17, 82, 13],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6, 17, 82, 13, 83],\n",
              " [5, 3, 15, 43, 1, 80, 81, 2, 9, 44, 1, 12, 8, 5, 6, 17, 82, 13, 83, 11],\n",
              " [14, 25],\n",
              " [14, 25, 35],\n",
              " [14, 25, 35, 1],\n",
              " [14, 25, 35, 1, 45],\n",
              " [14, 25, 35, 1, 45, 2],\n",
              " [14, 25, 35, 1, 45, 2, 30],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1, 12],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1, 12, 8],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1, 12, 8, 87],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1, 12, 8, 87, 88],\n",
              " [14, 25, 35, 1, 45, 2, 30, 84, 9, 85, 1, 10, 86, 44, 1, 12, 8, 87, 88, 46],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89,\n",
              "  90],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89,\n",
              "  90,\n",
              "  13],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89,\n",
              "  90,\n",
              "  13,\n",
              "  1],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89,\n",
              "  90,\n",
              "  13,\n",
              "  1,\n",
              "  26],\n",
              " [14,\n",
              "  25,\n",
              "  35,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  30,\n",
              "  84,\n",
              "  9,\n",
              "  85,\n",
              "  1,\n",
              "  10,\n",
              "  86,\n",
              "  44,\n",
              "  1,\n",
              "  12,\n",
              "  8,\n",
              "  87,\n",
              "  88,\n",
              "  46,\n",
              "  89,\n",
              "  90,\n",
              "  13,\n",
              "  1,\n",
              "  26,\n",
              "  18],\n",
              " [1, 4],\n",
              " [1, 4, 10],\n",
              " [1, 4, 10, 47],\n",
              " [1, 4, 10, 47, 91],\n",
              " [1, 4, 10, 47, 91, 92],\n",
              " [1, 4, 10, 47, 91, 92, 7],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6, 93],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6, 93, 94],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6, 93, 94, 19],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6, 93, 94, 19, 3],\n",
              " [1, 4, 10, 47, 91, 92, 7, 48, 49, 6, 93, 94, 19, 3, 18],\n",
              " [22, 95],\n",
              " [22, 95, 96],\n",
              " [22, 95, 96, 11],\n",
              " [22, 95, 96, 11, 49],\n",
              " [22, 95, 96, 11, 49, 97],\n",
              " [22, 95, 96, 11, 49, 97, 5],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21, 41],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21, 41, 9],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21, 41, 9, 99],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21, 41, 9, 99, 50],\n",
              " [22, 95, 96, 11, 49, 97, 5, 1, 17, 7, 98, 21, 41, 9, 99, 50, 100],\n",
              " [23, 2],\n",
              " [23, 2, 101],\n",
              " [23, 2, 101, 4],\n",
              " [23, 2, 101, 4, 102],\n",
              " [23, 2, 101, 4, 102, 50],\n",
              " [23, 2, 101, 4, 102, 50, 103],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104, 105],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104, 105, 14],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104, 105, 14, 24],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104, 105, 14, 24, 106],\n",
              " [23, 2, 101, 4, 102, 50, 103, 104, 105, 14, 24, 106, 43],\n",
              " [9, 107],\n",
              " [9, 107, 23],\n",
              " [9, 107, 23, 10],\n",
              " [9, 107, 23, 10, 1],\n",
              " [9, 107, 23, 10, 1, 3],\n",
              " [9, 107, 23, 10, 1, 3, 18],\n",
              " [9, 107, 23, 10, 1, 3, 18, 2],\n",
              " [9, 107, 23, 10, 1, 3, 18, 2, 108],\n",
              " [9, 107, 23, 10, 1, 3, 18, 2, 108, 109],\n",
              " [1, 51],\n",
              " [1, 51, 110],\n",
              " [1, 51, 110, 52],\n",
              " [1, 51, 110, 52, 27],\n",
              " [1, 51, 110, 52, 27, 111],\n",
              " [1, 51, 110, 52, 27, 111, 112],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3, 2],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3, 2, 114],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3, 2, 114, 115],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3, 2, 114, 115, 27],\n",
              " [1, 51, 110, 52, 27, 111, 112, 2, 113, 7, 1, 3, 2, 114, 115, 27, 11],\n",
              " [31, 8],\n",
              " [31, 8, 2],\n",
              " [31, 8, 2, 116],\n",
              " [31, 8, 2, 116, 52],\n",
              " [31, 8, 2, 116, 52, 27],\n",
              " [31, 8, 2, 116, 52, 27, 117],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121, 122],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121, 122, 21],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121, 122, 21, 1],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121, 122, 21, 1, 4],\n",
              " [31, 8, 2, 116, 52, 27, 117, 118, 16, 119, 7, 120, 121, 122, 21, 1, 4, 10],\n",
              " [31,\n",
              "  8,\n",
              "  2,\n",
              "  116,\n",
              "  52,\n",
              "  27,\n",
              "  117,\n",
              "  118,\n",
              "  16,\n",
              "  119,\n",
              "  7,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  21,\n",
              "  1,\n",
              "  4,\n",
              "  10,\n",
              "  28],\n",
              " [31,\n",
              "  8,\n",
              "  2,\n",
              "  116,\n",
              "  52,\n",
              "  27,\n",
              "  117,\n",
              "  118,\n",
              "  16,\n",
              "  119,\n",
              "  7,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  21,\n",
              "  1,\n",
              "  4,\n",
              "  10,\n",
              "  28,\n",
              "  123],\n",
              " [31,\n",
              "  8,\n",
              "  2,\n",
              "  116,\n",
              "  52,\n",
              "  27,\n",
              "  117,\n",
              "  118,\n",
              "  16,\n",
              "  119,\n",
              "  7,\n",
              "  120,\n",
              "  121,\n",
              "  122,\n",
              "  21,\n",
              "  1,\n",
              "  4,\n",
              "  10,\n",
              "  28,\n",
              "  123,\n",
              "  22],\n",
              " [1, 10],\n",
              " [1, 10, 2],\n",
              " [1, 10, 2, 124],\n",
              " [1, 10, 2, 124, 13],\n",
              " [1, 10, 2, 124, 13, 125],\n",
              " [1, 10, 2, 124, 13, 125, 19],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19, 11],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19, 11, 7],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19, 11, 7, 1],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19, 11, 7, 1, 128],\n",
              " [1, 10, 2, 124, 13, 125, 19, 11, 126, 1, 45, 2, 6, 127, 19, 11, 7, 1, 128, 2],\n",
              " [1,\n",
              "  10,\n",
              "  2,\n",
              "  124,\n",
              "  13,\n",
              "  125,\n",
              "  19,\n",
              "  11,\n",
              "  126,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  6,\n",
              "  127,\n",
              "  19,\n",
              "  11,\n",
              "  7,\n",
              "  1,\n",
              "  128,\n",
              "  2,\n",
              "  1],\n",
              " [1,\n",
              "  10,\n",
              "  2,\n",
              "  124,\n",
              "  13,\n",
              "  125,\n",
              "  19,\n",
              "  11,\n",
              "  126,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  6,\n",
              "  127,\n",
              "  19,\n",
              "  11,\n",
              "  7,\n",
              "  1,\n",
              "  128,\n",
              "  2,\n",
              "  1,\n",
              "  12],\n",
              " [1,\n",
              "  10,\n",
              "  2,\n",
              "  124,\n",
              "  13,\n",
              "  125,\n",
              "  19,\n",
              "  11,\n",
              "  126,\n",
              "  1,\n",
              "  45,\n",
              "  2,\n",
              "  6,\n",
              "  127,\n",
              "  19,\n",
              "  11,\n",
              "  7,\n",
              "  1,\n",
              "  128,\n",
              "  2,\n",
              "  1,\n",
              "  12,\n",
              "  8],\n",
              " [129, 130],\n",
              " [129, 130, 1],\n",
              " [129, 130, 1, 10],\n",
              " [129, 130, 1, 10, 47],\n",
              " [129, 130, 1, 10, 47, 1],\n",
              " [129, 130, 1, 10, 47, 1, 131],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2, 133],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2, 133, 134],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2, 133, 134, 9],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2, 133, 134, 9, 135],\n",
              " [129, 130, 1, 10, 47, 1, 131, 19, 132, 8, 2, 133, 134, 9, 135, 12],\n",
              " [3, 15],\n",
              " [3, 15, 16],\n",
              " [3, 15, 16, 4],\n",
              " [3, 15, 16, 4, 136],\n",
              " [3, 15, 16, 4, 136, 137],\n",
              " [3, 15, 16, 4, 136, 137, 138],\n",
              " [3, 15, 16, 4, 136, 137, 138, 139],\n",
              " [3, 15, 16, 4, 136, 137, 138, 139, 140],\n",
              " [22, 2],\n",
              " [22, 2, 141],\n",
              " [22, 2, 141, 5],\n",
              " [22, 2, 141, 5, 142],\n",
              " [22, 2, 141, 5, 142, 143],\n",
              " [22, 2, 141, 5, 142, 143, 3],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15, 146],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15, 146, 7],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15, 146, 7, 24],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15, 146, 7, 24, 147],\n",
              " [22, 2, 141, 5, 142, 143, 3, 144, 145, 15, 146, 7, 24, 147, 148],\n",
              " [14, 25],\n",
              " [14, 25, 149],\n",
              " [14, 25, 149, 150],\n",
              " [14, 25, 149, 150, 42],\n",
              " [14, 25, 149, 150, 42, 6],\n",
              " [14, 25, 149, 150, 42, 6, 151],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12, 8],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12, 8, 2],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12, 8, 2, 155],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12, 8, 2, 155, 156],\n",
              " [14, 25, 149, 150, 42, 6, 151, 13, 152, 153, 1, 154, 12, 8, 2, 155, 156, 16],\n",
              " [14,\n",
              "  25,\n",
              "  149,\n",
              "  150,\n",
              "  42,\n",
              "  6,\n",
              "  151,\n",
              "  13,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  154,\n",
              "  12,\n",
              "  8,\n",
              "  2,\n",
              "  155,\n",
              "  156,\n",
              "  16,\n",
              "  157],\n",
              " [14,\n",
              "  25,\n",
              "  149,\n",
              "  150,\n",
              "  42,\n",
              "  6,\n",
              "  151,\n",
              "  13,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  154,\n",
              "  12,\n",
              "  8,\n",
              "  2,\n",
              "  155,\n",
              "  156,\n",
              "  16,\n",
              "  157,\n",
              "  158],\n",
              " [14,\n",
              "  25,\n",
              "  149,\n",
              "  150,\n",
              "  42,\n",
              "  6,\n",
              "  151,\n",
              "  13,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  154,\n",
              "  12,\n",
              "  8,\n",
              "  2,\n",
              "  155,\n",
              "  156,\n",
              "  16,\n",
              "  157,\n",
              "  158,\n",
              "  9],\n",
              " [14,\n",
              "  25,\n",
              "  149,\n",
              "  150,\n",
              "  42,\n",
              "  6,\n",
              "  151,\n",
              "  13,\n",
              "  152,\n",
              "  153,\n",
              "  1,\n",
              "  154,\n",
              "  12,\n",
              "  8,\n",
              "  2,\n",
              "  155,\n",
              "  156,\n",
              "  16,\n",
              "  157,\n",
              "  158,\n",
              "  9,\n",
              "  4],\n",
              " [159, 26],\n",
              " [159, 26, 13],\n",
              " [159, 26, 13, 6],\n",
              " [159, 26, 13, 6, 160],\n",
              " [159, 26, 13, 6, 160, 161],\n",
              " [159, 26, 13, 6, 160, 161, 1],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162, 163],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162, 163, 7],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162, 163, 7, 164],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162, 163, 7, 164, 33],\n",
              " [159, 26, 13, 6, 160, 161, 1, 10, 28, 162, 163, 7, 164, 33, 51],\n",
              " [5, 165],\n",
              " [5, 165, 3],\n",
              " [5, 165, 3, 15],\n",
              " [5, 165, 3, 15, 2],\n",
              " [5, 165, 3, 15, 2, 6],\n",
              " [5, 165, 3, 15, 2, 6, 166],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29, 3],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29, 3, 170],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29, 3, 170, 32],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29, 3, 170, 32, 6],\n",
              " [5, 165, 3, 15, 2, 6, 166, 7, 167, 168, 9, 169, 4, 29, 3, 170, 32, 6, 20],\n",
              " [5,\n",
              "  165,\n",
              "  3,\n",
              "  15,\n",
              "  2,\n",
              "  6,\n",
              "  166,\n",
              "  7,\n",
              "  167,\n",
              "  168,\n",
              "  9,\n",
              "  169,\n",
              "  4,\n",
              "  29,\n",
              "  3,\n",
              "  170,\n",
              "  32,\n",
              "  6,\n",
              "  20,\n",
              "  171],\n",
              " [1, 36],\n",
              " [1, 36, 172],\n",
              " [1, 36, 172, 11],\n",
              " [1, 36, 172, 11, 37],\n",
              " [1, 36, 172, 11, 37, 4],\n",
              " [1, 36, 172, 11, 37, 4, 38],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174, 48],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174, 48, 7],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174, 48, 7, 175],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174, 48, 7, 175, 176],\n",
              " [1, 36, 172, 11, 37, 4, 38, 173, 10, 14, 174, 48, 7, 175, 176, 11],\n",
              " [23, 177],\n",
              " [23, 177, 2],\n",
              " [23, 177, 2, 178],\n",
              " [23, 177, 2, 178, 179],\n",
              " [23, 177, 2, 178, 179, 7],\n",
              " [23, 177, 2, 178, 179, 7, 28],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183, 184],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183, 184, 16],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183, 184, 16, 185],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183, 184, 16, 185, 186],\n",
              " [23, 177, 2, 178, 179, 7, 28, 180, 181, 182, 5, 183, 184, 16, 185, 186, 187],\n",
              " [23,\n",
              "  177,\n",
              "  2,\n",
              "  178,\n",
              "  179,\n",
              "  7,\n",
              "  28,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  5,\n",
              "  183,\n",
              "  184,\n",
              "  16,\n",
              "  185,\n",
              "  186,\n",
              "  187,\n",
              "  46],\n",
              " [23,\n",
              "  177,\n",
              "  2,\n",
              "  178,\n",
              "  179,\n",
              "  7,\n",
              "  28,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  5,\n",
              "  183,\n",
              "  184,\n",
              "  16,\n",
              "  185,\n",
              "  186,\n",
              "  187,\n",
              "  46,\n",
              "  188]]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "NhYtJYGPZ200"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "MdmZRd3SZ3yQ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uah-UbOVZ6eN",
        "outputId": "60371046-d343-419a-9595-751320977673"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   3,  15],\n",
              "       [  0,   0,   0, ...,   3,  15,  16],\n",
              "       [  0,   0,   0, ...,  15,  16,   4],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 185, 186, 187],\n",
              "       [  0,   0,   0, ..., 186, 187,  46],\n",
              "       [  0,   0,   0, ..., 187,  46, 188]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "uP8LCtYbaDXo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "J4W8Pk1NaTvA"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlz3PEuva7L4",
        "outputId": "e4b4506b-561f-4592-c4a4-22b0c71aac06"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFIptclda96j",
        "outputId": "45675691-e093-4ab7-ce8c-b34b381ba109"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363,)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "LrGg3lP_bBSD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr9JBN31bvqv",
        "outputId": "72c20c74-7350-4e73-d896-bfc42a6a63b7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(363, 189)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(max_len-1,)),\n",
        "    Embedding(vocab_size, 100),\n",
        "    LSTM(150),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "jvF1Jxz1cKVk",
        "outputId": "06851e89-efe0-4600-cf6f-0b7feec39621"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m18,900\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m189\u001b[0m)            │        \u001b[38;5;34m28,539\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,900</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,539</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m198,039\u001b[0m (773.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,039</span> (773.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m198,039\u001b[0m (773.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">198,039</span> (773.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUfzyDYAl53p",
        "outputId": "c4cfd5d8-addd-463f-a574-91d8d6fcbfc7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0791 - loss: 4.3991\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0650 - loss: 4.3262\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1151 - loss: 4.2578\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0969 - loss: 4.2313\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1592 - loss: 4.0324\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1245 - loss: 3.9810\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1459 - loss: 3.8217\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1428 - loss: 3.6853\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2263 - loss: 3.6040\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2002 - loss: 3.4772\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2080 - loss: 3.3508\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2966 - loss: 3.1209\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2966 - loss: 3.0209\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3104 - loss: 2.9015\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3754 - loss: 2.6963\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4090 - loss: 2.6281\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4858 - loss: 2.3522\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5301 - loss: 2.2897\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5074 - loss: 2.1535\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6099 - loss: 2.0410\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6117 - loss: 1.9228\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6385 - loss: 1.8249\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6950 - loss: 1.6899\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7684 - loss: 1.5863\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7727 - loss: 1.4747\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 1.4348\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7977 - loss: 1.3818\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8384 - loss: 1.2291\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8632 - loss: 1.1703\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8577 - loss: 1.1582\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9015 - loss: 1.0403\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9139 - loss: 0.9477\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.9440\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.9317\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.8212\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.7976\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.7664\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9397 - loss: 0.7203\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.6718\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9431 - loss: 0.6585\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.6121\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.5508\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.5540\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9694 - loss: 0.5088\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.4919\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9570 - loss: 0.4833\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.4692\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9730 - loss: 0.4291\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.4527\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9672 - loss: 0.4182\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.3854\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9653 - loss: 0.3937\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9767 - loss: 0.3545\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.3542\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9764 - loss: 0.3246\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.3038\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.3012\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.2915\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.2722\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9576 - loss: 0.2931\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.2599\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.2439\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.2411\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.2473\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.2333\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9745 - loss: 0.2298\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.2183\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.2081\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.1978\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.2103\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9793 - loss: 0.1869\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.1884\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1934\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.1805\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1870\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9591 - loss: 0.1885\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.1628\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9691 - loss: 0.1608\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.1762\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.1636\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9717 - loss: 0.1533\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9607 - loss: 0.1722\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.1549\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1651\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1415\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1383\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9712 - loss: 0.1484\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.1288\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9662 - loss: 0.1378\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.1524\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.1242\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9635 - loss: 0.1286\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.1196\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9577 - loss: 0.1439\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.1271\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.1216\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.1281\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.1276\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0975\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.1018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6a6ed5d3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "text= \"If we change the order\"\n",
        "for i in range(5):\n",
        "\n",
        " token_text=tokenizer.texts_to_sequences([text])[0]\n",
        " padded_token_text = pad_sequences([token_text],\n",
        "                                  maxlen=max_len-1,\n",
        "                                  padding='pre')\n",
        "\n",
        "\n",
        " pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        " for word, index in tokenizer.word_index.items():\n",
        "  if index == pos:\n",
        "   text = text +\" \"+word\n",
        "   print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yP1JBcJmXa2",
        "outputId": "1a7152d7-52a0-45f6-c449-ae219b30a465"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "If we change the order randomly\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "If we change the order randomly the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "If we change the order randomly the sentence\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "If we change the order randomly the sentence will\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "If we change the order randomly the sentence will lose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "GR5rAhbgn3AR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}